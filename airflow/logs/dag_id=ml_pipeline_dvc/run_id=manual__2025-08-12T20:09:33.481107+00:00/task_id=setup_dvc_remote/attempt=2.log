[2025-08-12T20:25:30.570+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-12T20:25:30.818+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ml_pipeline_dvc.setup_dvc_remote manual__2025-08-12T20:09:33.481107+00:00 [queued]>
[2025-08-12T20:25:30.850+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ml_pipeline_dvc.setup_dvc_remote manual__2025-08-12T20:09:33.481107+00:00 [queued]>
[2025-08-12T20:25:30.851+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2025-08-12T20:25:30.913+0000] {taskinstance.py:2330} INFO - Executing <Task(BashOperator): setup_dvc_remote> on 2025-08-12 20:09:33.481107+00:00
[2025-08-12T20:25:31.046+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=63) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-08-12T20:25:31.074+0000] {standard_task_runner.py:63} INFO - Started process 66 to run task
[2025-08-12T20:25:31.074+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'ml_pipeline_dvc', 'setup_dvc_remote', 'manual__2025-08-12T20:09:33.481107+00:00', '--job-id', '164', '--raw', '--subdir', 'DAGS_FOLDER/train_pipeline_dag.py', '--cfg-path', '/tmp/tmpkafukehx']
[2025-08-12T20:25:31.136+0000] {standard_task_runner.py:91} INFO - Job 164: Subtask setup_dvc_remote
[2025-08-12T20:25:31.925+0000] {task_command.py:426} INFO - Running <TaskInstance: ml_pipeline_dvc.setup_dvc_remote manual__2025-08-12T20:09:33.481107+00:00 [running]> on host fac193a1167f
[2025-08-12T20:25:32.251+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='yas' AIRFLOW_CTX_DAG_ID='ml_pipeline_dvc' AIRFLOW_CTX_TASK_ID='setup_dvc_remote' AIRFLOW_CTX_EXECUTION_DATE='2025-08-12T20:09:33.481107+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-08-12T20:09:33.481107+00:00'
[2025-08-12T20:25:32.266+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-12T20:25:32.511+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-08-12T20:25:32.518+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n        cd /opt/***/ml_pipeline\n        aws --endpoint-url http://minio:9000 s3 ls s3://mlflow-artifacts\n        dvc remote remove minio || true\n        dvc remote add -d minio s3://mlflow-artifacts\n        dvc remote modify minio endpointurl http://minio:9000\n        dvc remote modify minio access_key_id minioadmin\n        dvc remote modify minio secret_access_key minioadmin\n        dvc remote modify minio use_ssl false\n        export AWS_ACCESS_KEY_ID=minioadmin\n        export AWS_SECRET_ACCESS_KEY=minioadmin\n        export AWS_ENDPOINT_URL=http://minio:9000\n        dvc push --verbose\n        echo "=== DVC CONFIG AFTER SETUP ==="\n        cat .dvc/config\n        dvc repro preprocess -v\n        ']
[2025-08-12T20:25:32.563+0000] {subprocess.py:86} INFO - Output:
[2025-08-12T20:25:36.921+0000] {subprocess.py:93} INFO -                            PRE data/
[2025-08-12T20:25:36.923+0000] {subprocess.py:93} INFO -                            PRE metadata/
[2025-08-12T20:25:36.924+0000] {subprocess.py:93} INFO -                            PRE preprocess/
[2025-08-12T20:25:39.947+0000] {subprocess.py:93} INFO - ERROR: configuration error - config file error: expected 'url' for dictionary value @ data['remote']['minio']
[2025-08-12T20:25:44.973+0000] {subprocess.py:93} INFO - Setting 'minio' as a default remote.
[2025-08-12T20:25:44.988+0000] {subprocess.py:93} INFO - ERROR: configuration error - config file error: remote 'minio' already exists. Use `-f|--force` to overwrite it.
[2025-08-12T20:26:01.078+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:01,078 DEBUG: v3.61.0 (pip), CPython 3.12.3 on Linux-6.6.31-linuxkit-x86_64-with-glibc2.36
[2025-08-12T20:26:01.084+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:01,079 DEBUG: command: /home/***/.local/bin/dvc push --verbose
[2025-08-12T20:26:04.756+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:04,755 DEBUG: Lockfile 'dvc.lock' needs to be updated.
[2025-08-12T20:26:05.930+0000] {subprocess.py:93} INFO - Everything is up to date.
[2025-08-12T20:26:05.934+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:05,934 DEBUG: Analytics is enabled.
[2025-08-12T20:26:05.990+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:05,989 DEBUG: Trying to spawn ['daemon', 'analytics', '/tmp/tmp70podk62', '-v']
[2025-08-12T20:26:05.998+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:05,997 DEBUG: Spawned ['daemon', 'analytics', '/tmp/tmp70podk62', '-v'] with pid 350
[2025-08-12T20:26:06.169+0000] {subprocess.py:93} INFO - === DVC CONFIG AFTER SETUP ===
[2025-08-12T20:26:06.172+0000] {subprocess.py:93} INFO - [core]
[2025-08-12T20:26:06.173+0000] {subprocess.py:93} INFO -     remote = minio
[2025-08-12T20:26:06.174+0000] {subprocess.py:93} INFO - ['remote "minio"']
[2025-08-12T20:26:06.175+0000] {subprocess.py:93} INFO -     url = s3://mlflow-artifacts
[2025-08-12T20:26:06.175+0000] {subprocess.py:93} INFO -     endpointurl = http://minio:9000
[2025-08-12T20:26:06.176+0000] {subprocess.py:93} INFO -     access_key_id = minioadmin
[2025-08-12T20:26:06.176+0000] {subprocess.py:93} INFO -     secret_access_key = minioadmin
[2025-08-12T20:26:06.177+0000] {subprocess.py:93} INFO -     use_ssl = false
[2025-08-12T20:26:06.750+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:06,749 DEBUG: v3.61.0 (pip), CPython 3.12.3 on Linux-6.6.31-linuxkit-x86_64-with-glibc2.36
[2025-08-12T20:26:06.751+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:06,750 DEBUG: command: /home/***/.local/bin/dvc repro preprocess -v
[2025-08-12T20:26:10.086+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:10,086 DEBUG: Assuming 'preprocess' to be a stage inside 'dvc.yaml'
[2025-08-12T20:26:10.247+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:10,246 DEBUG: Lockfile 'dvc.lock' needs to be updated.
[2025-08-12T20:26:11.609+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:11,602 ERROR: failed to reproduce 'preprocess': 'mlflow-artifacts/preprocess/v20250812_055140/preprocess_metadata.json' is busy, it is being blocked by:
[2025-08-12T20:26:11.611+0000] {subprocess.py:93} INFO -   (PID 328): /home/***/.local/bin/dvc repro preprocess -v
[2025-08-12T20:26:11.613+0000] {subprocess.py:93} INFO -   (PID 328): /home/***/.local/bin/dvc repro preprocess -v
[2025-08-12T20:26:11.614+0000] {subprocess.py:93} INFO - 
[2025-08-12T20:26:11.614+0000] {subprocess.py:93} INFO - If there are no processes with such PIDs, you can manually remove '/opt/***/ml_pipeline/.dvc/tmp/rwlock' and try again.
[2025-08-12T20:26:11.615+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-08-12T20:26:11.616+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/repo/reproduce.py", line 187, in _reproduce
[2025-08-12T20:26:11.616+0000] {subprocess.py:93} INFO -     ret = repro_fn(stage, upstream=upstream, force=force_stage, **kwargs)
[2025-08-12T20:26:11.617+0000] {subprocess.py:93} INFO -           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-08-12T20:26:11.618+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/repo/reproduce.py", line 117, in _reproduce_stage
[2025-08-12T20:26:11.618+0000] {subprocess.py:93} INFO -     ret = stage.reproduce(**kwargs)
[2025-08-12T20:26:11.619+0000] {subprocess.py:93} INFO -           ^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-08-12T20:26:11.620+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/funcy/decorators.py", line 47, in wrapper
[2025-08-12T20:26:11.620+0000] {subprocess.py:93} INFO -     return deco(call, *dargs, **dkwargs)
[2025-08-12T20:26:11.621+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-08-12T20:26:11.622+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/stage/decorators.py", line 36, in rwlocked
[2025-08-12T20:26:11.623+0000] {subprocess.py:93} INFO -     with rwlock(
[2025-08-12T20:26:11.624+0000] {subprocess.py:93} INFO -   File "/usr/local/lib/python3.12/contextlib.py", line 137, in __enter__
[2025-08-12T20:26:11.624+0000] {subprocess.py:93} INFO -     return next(self.gen)
[2025-08-12T20:26:11.625+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^
[2025-08-12T20:26:11.626+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/rwlock.py", line 210, in rwlock
[2025-08-12T20:26:11.626+0000] {subprocess.py:93} INFO -     _check_blockers(tmp_dir, lock, info, mode="write", waiters=read + write)
[2025-08-12T20:26:11.627+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/rwlock.py", line 125, in _check_blockers
[2025-08-12T20:26:11.628+0000] {subprocess.py:93} INFO -     raise LockError(
[2025-08-12T20:26:11.629+0000] {subprocess.py:93} INFO - dvc.lock.LockError: 'mlflow-artifacts/preprocess/v20250812_055140/preprocess_metadata.json' is busy, it is being blocked by:
[2025-08-12T20:26:11.630+0000] {subprocess.py:93} INFO -   (PID 328): /home/***/.local/bin/dvc repro preprocess -v
[2025-08-12T20:26:11.630+0000] {subprocess.py:93} INFO -   (PID 328): /home/***/.local/bin/dvc repro preprocess -v
[2025-08-12T20:26:11.631+0000] {subprocess.py:93} INFO - 
[2025-08-12T20:26:11.632+0000] {subprocess.py:93} INFO - If there are no processes with such PIDs, you can manually remove '/opt/***/ml_pipeline/.dvc/tmp/rwlock' and try again.
[2025-08-12T20:26:11.633+0000] {subprocess.py:93} INFO - 
[2025-08-12T20:26:11.634+0000] {subprocess.py:93} INFO - The above exception was the direct cause of the following exception:
[2025-08-12T20:26:11.634+0000] {subprocess.py:93} INFO - 
[2025-08-12T20:26:11.635+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-08-12T20:26:11.636+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/cli/__init__.py", line 211, in main
[2025-08-12T20:26:11.637+0000] {subprocess.py:93} INFO -     ret = cmd.do_run()
[2025-08-12T20:26:11.638+0000] {subprocess.py:93} INFO -           ^^^^^^^^^^^^
[2025-08-12T20:26:11.638+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/cli/command.py", line 30, in do_run
[2025-08-12T20:26:11.639+0000] {subprocess.py:93} INFO -     return self.run()
[2025-08-12T20:26:11.640+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^
[2025-08-12T20:26:11.640+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/commands/repro.py", line 11, in run
[2025-08-12T20:26:11.641+0000] {subprocess.py:93} INFO -     stages = self.repo.reproduce(**self._common_kwargs, **self._repro_kwargs)
[2025-08-12T20:26:11.642+0000] {subprocess.py:93} INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-08-12T20:26:11.642+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/repo/__init__.py", line 58, in wrapper
[2025-08-12T20:26:11.643+0000] {subprocess.py:93} INFO -     return f(repo, *args, **kwargs)
[2025-08-12T20:26:11.644+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^
[2025-08-12T20:26:11.644+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/repo/scm_context.py", line 143, in run
[2025-08-12T20:26:11.645+0000] {subprocess.py:93} INFO -     return method(repo, *args, **kw)
[2025-08-12T20:26:11.646+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-08-12T20:26:11.647+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/repo/reproduce.py", line 248, in reproduce
[2025-08-12T20:26:11.647+0000] {subprocess.py:93} INFO -     return _reproduce(steps, graph=graph, on_error=on_error or "fail", **kwargs)
[2025-08-12T20:26:11.648+0000] {subprocess.py:93} INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-08-12T20:26:11.649+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/repo/reproduce.py", line 191, in _reproduce
[2025-08-12T20:26:11.650+0000] {subprocess.py:93} INFO -     _raise_error(exc, stage)
[2025-08-12T20:26:11.651+0000] {subprocess.py:93} INFO -   File "/home/***/.local/lib/python3.12/site-packages/dvc/repo/reproduce.py", line 155, in _raise_error
[2025-08-12T20:26:11.652+0000] {subprocess.py:93} INFO -     raise ReproductionError(f"failed to reproduce{segment} {names}") from exc
[2025-08-12T20:26:11.652+0000] {subprocess.py:93} INFO - dvc.exceptions.ReproductionError: failed to reproduce 'preprocess'
[2025-08-12T20:26:11.653+0000] {subprocess.py:93} INFO - 
[2025-08-12T20:26:11.654+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:11,615 DEBUG: Analytics is enabled.
[2025-08-12T20:26:11.716+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:11,716 DEBUG: Trying to spawn ['daemon', 'analytics', '/tmp/tmpvxyfmfoq', '-v']
[2025-08-12T20:26:11.725+0000] {subprocess.py:93} INFO - 2025-08-12 20:26:11,724 DEBUG: Spawned ['daemon', 'analytics', '/tmp/tmpvxyfmfoq', '-v'] with pid 393
[2025-08-12T20:26:12.016+0000] {subprocess.py:97} INFO - Command exited with return code 255
[2025-08-12T20:26:12.018+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-12T20:26:12.041+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 243, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 255.
[2025-08-12T20:26:12.056+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=ml_pipeline_dvc, task_id=setup_dvc_remote, run_id=manual__2025-08-12T20:09:33.481107+00:00, execution_date=20250812T200933, start_date=20250812T202530, end_date=20250812T202612
[2025-08-12T20:26:12.112+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 164 for task setup_dvc_remote (Bash command failed. The command returned a non-zero exit code 255.; 66)
[2025-08-12T20:26:12.167+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-08-12T20:26:12.229+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-08-12T20:26:12.271+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
